{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anil-Chalumuri/GenAINotes/blob/main/Weaviate_Vector_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcR2ogx3UNWm",
        "outputId": "a24824b0-0577-423e-f972-f840fc9b13a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.5.4-py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.31.0)\n",
            "Collecting httpx==0.27.0 (from weaviate-client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting validators==0.22.0 (from weaviate-client)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.6.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.62.1)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.62.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx==0.27.0->weaviate-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.0->weaviate-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx==0.27.0->weaviate-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (42.0.5)\n",
            "Collecting protobuf>=4.21.6 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (67.7.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx==0.27.0->weaviate-client) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
            "Installing collected packages: validators, protobuf, h11, httpcore, grpcio-tools, grpcio-health-checking, httpx, authlib, weaviate-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.0 grpcio-health-checking-1.62.1 grpcio-tools-1.62.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 protobuf-4.25.3 validators-0.22.0 weaviate-client-4.5.4\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-text-splitters-0.0.1 langsmith-0.1.40 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-1.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate-client\n",
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://console.weaviate.cloud/"
      ],
      "metadata": {
        "id": "U7b_8c0gX0qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "8AjYAduCwc6Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "BIvw4-3swjbt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEAVIATE_API_KEY = \"********\"\n",
        "WEAVIATE_CLUSTER = \"*******\""
      ],
      "metadata": {
        "id": "gFv2J40pUWVp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Reading"
      ],
      "metadata": {
        "id": "g1cyA4LVYFXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "!pip install unstructured\n",
        "!pip install \"unstructed[pdf]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydqw5kc1zwxW",
        "outputId": "b0a3ca1a-cc94-494c-8d71-25befb95cc65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.13.1-py3-none-any.whl (680 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.1/680.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.4)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.10.0)\n",
            "Collecting unstructured-client<=0.18.0 (from unstructured)\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (3.3.2)\n",
            "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client<=0.18.0->unstructured)\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: idna>=3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (3.6)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client<=0.18.0->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: marshmallow>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (3.21.1)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (1.0.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (1.16.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured-client<=0.18.0->unstructured) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.2)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=452f82ffac3f6ef2997d7790b8a11ed06258ce5025ff1adc6459a1a73b813feb\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, langdetect, jsonpath-python, emoji, backoff, dataclasses-json-speakeasy, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 dataclasses-json-speakeasy-0.5.11 emoji-2.11.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.7.0 unstructured-0.13.1 unstructured-client-0.18.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement unstructed[pdf] (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for unstructed[pdf]\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "Wu9o2myHzHZh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "loader = PyPDFDirectoryLoader(\"data\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "To4_IwCGYEW4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv7iDCb8aC6o",
        "outputId": "f1f333da-f10a-46cf-f29b-7172922ce5e4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Importance\\nand\\nthe\\nuse\\nof\\ncorrelation\\nin\\nStatistics\\nIntroduction\\nCorrelation\\nis\\na\\nstatistical\\nmeasure\\nthat\\nexpresses\\nthe\\nextent\\nto\\nwhich\\ntwo\\nvariables\\nare\\nlinearly\\nrelated.\\nIt\\nis\\na\\ncommon\\ntool\\nfor\\ndescribing\\nsimple\\nrelationships\\nwithout\\nmaking\\na\\nstatement\\nabout\\ncause\\nand\\neffect.\\nCorrelation\\ncoefficients\\nrange\\nfrom\\n-1\\nto\\n1,\\nwith\\na\\nvalue\\nof\\n0\\nindicating\\nno\\nlinear\\nrelationship\\nbetween\\nthe\\ntwo\\nvariables,\\na\\nvalue\\nof\\n1\\nindicating\\na\\nperfect\\npositive\\nlinear\\nrelationship,\\nand\\na\\nvalue\\nof\\n-1\\nindicating\\na\\nperfect\\nnegative\\nlinear\\nrelationship.\\nCorrelation\\nis\\nimportant\\nin\\nstatistics\\nbecause\\nit\\ncan\\nbe\\nused\\nto\\n1.\\nIdentify\\nrelationships\\nbetween\\nvariables:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nwhether\\nthere\\nis\\na\\nrelationship\\nbetween\\ntwo\\nvariables,\\nand\\nif\\nso,\\nwhether\\nthe\\nrelationship\\nis\\npositive\\nor\\nnegative.\\nThis\\ninformation\\ncan\\nbe\\nuseful\\nfor\\nunderstanding\\nthe\\nrelationships\\nbetween\\ndifferent\\nfactors\\nin\\na\\ncomplex\\nsystem.\\n2.\\nMake\\npredictions:\\nIf\\nthere\\nis\\na\\nstrong\\ncorrelation\\nbetween\\ntwo\\nvariables,\\nit\\nis\\npossible\\nto\\nuse\\nthe\\nvalue\\nof\\none\\nvariable\\nto\\npredict\\nthe\\nvalue\\nof\\nthe\\nother\\nvariable.\\nThis\\ncan\\nbe\\nuseful\\nfor\\nmaking\\npredictions\\nin\\na\\nvariety\\nof\\nfields,\\nsuch\\nas\\nbusiness,\\nfinance,\\nand\\nmedicine.\\n3.\\nDevelop\\ncausal\\nmodels:\\nCorrelation\\ncan\\nbe\\nused\\nas\\na\\nstarting\\npoint\\nfor\\ndeveloping\\ncausal\\nmodels,\\nwhich\\nare\\nmodels\\nthat\\ndescribe\\nhow\\nchanges\\nin\\none\\nvariable\\ncause\\nchanges\\nin\\nother\\nvariables.\\nCausal\\nmodels\\ncan\\nbe\\nused\\nto\\nmake\\nmore\\naccurate\\npredictions\\nand\\nto\\ndevelop\\ninterventions\\nto\\nchange\\nthe\\nvalues\\nof\\nspecific\\nvariables.', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf', 'page': 0}),\n",
              " Document(page_content='Correlation\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nincluding\\n1.\\nBusiness:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nbusiness\\nvariables,\\nsuch\\nas\\nsales,\\nadvertising\\nspending,\\nand\\ncustomer\\nsatisfaction.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nmake\\nbetter\\nbusiness\\ndecisions,\\nsuch\\nas\\nhow\\nto\\nallocate\\nmarketing\\nresources.\\n2.\\nFinance:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nfinancial\\nassets,\\nsuch\\nas\\nstocks,\\nbonds,\\nand\\ncommodities.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nbuild\\ndiversified\\nportfolios\\nthat\\nreduce\\nrisk.\\n3.\\nMedicine:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nmedical\\nvariables,\\nsuch\\nas\\nrisk\\nfactors\\nfor\\ndiseases\\nand\\nthe\\neffectiveness\\nof\\ntreatments.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nimprove\\nthe\\nprevention,\\ndiagnosis,\\nand\\ntreatment\\nof\\ndiseases.\\n4.\\nPsychology:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\npsychological\\nvariables,\\nsuch\\nas\\npersonality\\ntraits,\\ncognitive\\nabilities,\\nand\\nmental\\ndisorders.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\ndevelop\\nbetter\\npsychological\\nassessments\\nand\\ntreatments.\\nHow\\ncorrelation\\nis\\nused\\nin\\nthe\\nreal\\nworld\\n1.\\nA\\nmarketing\\nmanager\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nadvertising\\nspending\\nand\\nsales.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndecide\\nhow\\nmuch\\nmoney\\nto\\nallocate\\nto\\nadvertising.\\n2.\\nA\\nfinancial\\nanalyst\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nthe\\nreturns\\nof\\ndifferent\\nstocks.\\nThis\\ninformation\\ncould\\nbe', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf', 'page': 1}),\n",
              " Document(page_content='used\\nto\\nbuild\\na\\nportfolio\\nof\\nstocks\\nthat\\nis\\ndiversified\\nand\\nhas\\na\\nlower\\noverall\\nrisk.\\n3.\\nA\\nmedical\\nresearcher\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nsmoking\\nand\\nlung\\ncancer.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\npublic\\nhealth\\ncampaigns\\nto\\ndiscourage\\nsmoking.\\n4.\\nA\\npsychologist\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nanxiety\\nand\\ndepression.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\nmore\\neffective\\ntreatments\\nfor\\nanxiety\\nand\\ndepression.\\nConclusion\\nIt\\nis\\nimportant\\nto\\nnote\\nthat\\ncorrelation\\ndoes\\nnot\\nequal\\ncausation.\\nJust\\nbecause\\ntwo\\nvariables\\nare\\ncorrelated\\ndoes\\nnot\\nmean\\nthat\\none\\nvariable\\ncauses\\nthe\\nother .\\nFor\\nexample,\\nthere\\nis\\na\\nstrong\\ncorrelation\\nbetween\\nice\\ncream\\nsales\\nand\\nshark\\nattacks.\\nHowever ,\\nthis\\ndoes\\nnot\\nmean\\nthat\\neating\\nice\\ncream\\ncauses\\nshark\\nattacks.\\nInstead,\\nthere\\nis\\nlikely\\na\\nthird\\nvariable,\\nsuch\\nas\\nhot\\nweather ,\\nthat\\ncauses\\nboth\\nice\\ncream\\nsales\\nand\\nshark\\nattacks\\nto\\nincrease.\\nOverall,\\ncorrelation\\nis\\na\\npowerful\\nstatistical\\ntool\\nthat\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\nvariables,\\nmake\\npredictions,\\nand\\ndevelop\\ncausal\\nmodels.\\nIt\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nto\\nmake\\nbetter\\ndecisions\\nand\\nimprove\\noutcomes.', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf', 'page': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitting"
      ],
      "metadata": {
        "id": "r9yWlFvXZGig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "docs = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "JiGn3GNuZFtn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOHRyXobaF1P",
        "outputId": "d93f1df4-b8d9-4c63-ff49-d0909dafb42b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Convertion"
      ],
      "metadata": {
        "id": "LrolWA93aXAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "n_MB0iFYaH2Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtiVCLcnaqip",
        "outputId": "da734616-e818-4d90-b742-ffadc22ee0aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x78749b67fa30>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x78749b727490>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database Storage"
      ],
      "metadata": {
        "id": "rPT67TZpbFFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from langchain.vectorstores import Weaviate\n",
        "\n",
        "#Connect to weaviate Cluster\n",
        "auth_config = weaviate.auth.AuthApiKey(api_key = WEAVIATE_API_KEY)\n",
        "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
        "\n",
        "client = weaviate.Client(\n",
        "    url = WEAVIATE_URL,\n",
        "    additional_headers = {\"X-OpenAI-Api-key\": OPENAI_API_KEY},\n",
        "    auth_client_secret = auth_config,\n",
        "    startup_period = 10\n",
        ")"
      ],
      "metadata": {
        "id": "D-yIlvmKavmo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.is_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5etuMdHcPGR",
        "outputId": "c05a86b3-b3e2-4ac6-c2d2-e935cb5420ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define input structure\n",
        "client.schema.delete_all()\n",
        "client.schema.get()\n",
        "schema = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"class\": \"Chatbot\",\n",
        "            \"description\": \"Documents for chatbot\",\n",
        "            \"vectorizer\": \"text2vec-openai\",\n",
        "            \"moduleConfig\": {\"text2vec-openai\": {\"model\": \"ada\", \"type\": \"text\"}},\n",
        "            \"properties\": [\n",
        "                {\n",
        "                    \"dataType\": [\"text\"],\n",
        "                    \"description\": \"The content of the paragraph\",\n",
        "                    \"moduleConfig\": {\n",
        "                        \"text2vec-openai\": {\n",
        "                            \"skip\": False,\n",
        "                            \"vectorizePropertyName\": False,\n",
        "                        }\n",
        "                    },\n",
        "                    \"name\": \"content\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "}\n",
        "\n",
        "client.schema.create(schema)\n",
        "vectorstore = Weaviate(client, \"Chatbot\", \"content\", attributes=[\"source\"])"
      ],
      "metadata": {
        "id": "WEWOVbyNdNdR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load text into the vectorstore\n",
        "text_meta_pair = [(doc.page_content, doc.metadata) for doc in docs]\n",
        "texts, meta = list(zip(*text_meta_pair))\n",
        "vectorstore.add_texts(texts, meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqaBpQvXeNsJ",
        "outputId": "76c93a34-0323-46b8-909e-718587ba71fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 429 error: Rate limit reached for text-embedding-ada-002 in organization org-Y21bhgK3C3WGP9uvwYGmMhYS on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 429 error: Rate limit reached for text-embedding-ada-002 in organization org-Y21bhgK3C3WGP9uvwYGmMhYS on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 429 error: Rate limit reached for text-embedding-ada-002 in organization org-Y21bhgK3C3WGP9uvwYGmMhYS on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.'}]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01ed8707-512b-45b4-bcb0-ff1fd62f09e7',\n",
              " 'df47129d-75c9-4350-9d11-c34aa78580fd',\n",
              " 'f36844c1-db90-48d1-933e-7cf9c41fc2f5',\n",
              " '3e2b4fdc-a66f-48b4-ae7a-79b44a29bf44',\n",
              " 'f6134d04-a9ff-44f3-84b1-b52433dd05b8',\n",
              " 'c1053c7b-f0c3-4cc6-9f9c-868d58ac857f']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity Measurement"
      ],
      "metadata": {
        "id": "BktCnFkRe0Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is a correlation?\"\n",
        "\n",
        "# retrieve text related to the query\n",
        "docs = vectorstore.similarity_search(query, top_k=3)"
      ],
      "metadata": {
        "id": "pLZg7Pr5edlh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIs3FvBie4w4",
        "outputId": "edb0d754-21b9-48e5-e54a-9d869a7cfe94"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='used\\nto\\nbuild\\na\\nportfolio\\nof\\nstocks\\nthat\\nis\\ndiversified\\nand\\nhas\\na\\nlower\\noverall\\nrisk.\\n3.\\nA\\nmedical\\nresearcher\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nsmoking\\nand\\nlung\\ncancer.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\npublic\\nhealth\\ncampaigns\\nto\\ndiscourage\\nsmoking.\\n4.\\nA\\npsychologist\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nanxiety\\nand\\ndepression.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\nmore\\neffective\\ntreatments\\nfor\\nanxiety\\nand\\ndepression.\\nConclusion\\nIt\\nis\\nimportant\\nto\\nnote\\nthat\\ncorrelation\\ndoes\\nnot\\nequal\\ncausation.\\nJust\\nbecause\\ntwo\\nvariables\\nare\\ncorrelated\\ndoes\\nnot\\nmean\\nthat\\none\\nvariable\\ncauses\\nthe\\nother .\\nFor\\nexample,\\nthere\\nis\\na\\nstrong\\ncorrelation\\nbetween\\nice\\ncream\\nsales\\nand\\nshark\\nattacks.\\nHowever ,\\nthis\\ndoes\\nnot\\nmean\\nthat\\neating\\nice\\ncream\\ncauses\\nshark\\nattacks.\\nInstead,\\nthere\\nis\\nlikely\\na\\nthird\\nvariable,\\nsuch\\nas\\nhot\\nweather ,\\nthat\\ncauses\\nboth\\nice\\ncream\\nsales\\nand\\nshark\\nattacks\\nto\\nincrease.\\nOverall,\\ncorrelation\\nis\\na\\npowerful\\nstatistical\\ntool\\nthat\\ncan', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf'}),\n",
              " Document(page_content='Correlation\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nincluding\\n1.\\nBusiness:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nbusiness\\nvariables,\\nsuch\\nas\\nsales,\\nadvertising\\nspending,\\nand\\ncustomer\\nsatisfaction.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nmake\\nbetter\\nbusiness\\ndecisions,\\nsuch\\nas\\nhow\\nto\\nallocate\\nmarketing\\nresources.\\n2.\\nFinance:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nfinancial\\nassets,\\nsuch\\nas\\nstocks,\\nbonds,\\nand\\ncommodities.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nbuild\\ndiversified\\nportfolios\\nthat\\nreduce\\nrisk.\\n3.\\nMedicine:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nmedical\\nvariables,\\nsuch\\nas\\nrisk\\nfactors\\nfor\\ndiseases\\nand\\nthe\\neffectiveness\\nof\\ntreatments.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nimprove\\nthe\\nprevention,\\ndiagnosis,\\nand\\ntreatment\\nof\\ndiseases.\\n4.\\nPsychology:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\npsychological\\nvariables,\\nsuch\\nas\\npersonality\\ntraits,\\ncognitive\\nabilities,\\nand\\nmental\\ndisorders.\\nThis', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf'}),\n",
              " Document(page_content='tool\\nthat\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\nvariables,\\nmake\\npredictions,\\nand\\ndevelop\\ncausal\\nmodels.\\nIt\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nto\\nmake\\nbetter\\ndecisions\\nand\\nimprove\\noutcomes.', metadata={'source': 'data/Report - Importance and the use of correlation in Statistics.pdf'}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)8Related Work-MultiGrasp (Redmon et. al 2014)-Similar to YOLO-A much simpler task (only needs to predict object not multiple objects)', metadata={'source': 'data/yolo.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom chatbot"
      ],
      "metadata": {
        "id": "dwNOu59BfGP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "yP_qHtO7fV8n"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define chain\n",
        "chain = load_qa_chain(\n",
        "    OpenAI(),\n",
        "    chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "5d5qA06ifY4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986e2307-fe47-492a-9083-fe2f0ca693bf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create answer\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7KuVrWoDeeF4",
        "outputId": "a36b55ee-b762-4c53-f24b-4923eccd5908"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Correlation is a statistical measure that describes the relationship between two or more variables. It is used to determine if there is a connection between these variables and if so, the strength and direction of that connection. Correlation does not necessarily imply causation, but can provide valuable information for predicting and understanding relationships between variables.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VEtPH4keeDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}